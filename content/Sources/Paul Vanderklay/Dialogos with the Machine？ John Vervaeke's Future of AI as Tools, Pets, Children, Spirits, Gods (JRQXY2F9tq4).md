https://youtubetranscript.com/?v=JRQXY2F9tq4

 Hi, this is Paul. John Vervecki did a hour and 46 minute video. Now this is a little different from what John often does as he notes right at the beginning. This isn't voices with Vervecki. It's much more of a video lecture. It's a presentation. He's got it organized. It's not like Awakening from the Meaning Crisis or After Socrates where he's sort of in a classroom setting. It's similar to perhaps some of what I do. A little different too in some ways. I usually don't. Maybe it's a rough draft for Sunday or something like that. But he presents a number of thoughts on AI and, well, he frames it with respect to thresholds. Now I've already heard a little bit of chatter around this. I'm going to start at the end, which is I'm going to start to set up the end and then I want to go back to the beginning. Well, why? Well, some of the big things are at the end and a lot of the stuff at the front end, I think, is... How can I say it? This stuff is so hard to talk about for lots of reasons. Sam, both on my live stream and he's right now on a live stream with Jacob on his channel. Sam makes an excellent point that part of why we are having this global anxiety about AI is because we as human beings get anxious about threats. All the way at the beginning, John quite rightly notes that we are very accustomed to something similar to AI. Part of what this video provoked in me was a lot of thinking with respect to the deceptions that we generally work beneath. Some of the major deceptions being that we as individuals have a lot of control over the big things that are going on collectively and communally. Even while I do videos, I'm almost always listening to a whole variety of historical books. I love history books. I just started one on the Napoleonic Wars. One of the amazing things about the end of the 18th century and the beginning of the 19th century is these colossal titanic changes just sweep over Europe. The most powerful people in Europe do not want to see these changes happen and yet unwittingly fall into these changes. I just finished listening to the Rest is History's take on the fall of Saigon and the retreat of America from Vietnam at the end of the Vietnamese War. Again, Vietnam, Cambodia, Second World War. The way history seems to work is that as John says quite earlier in this video, what religious communities have long paid attention to is that other layers of agency are impacting history in a way that even the most powerful individuals certainly participate in but by no means control. There's going to be a lot of question in the modern realm about what on earth we mean by collective agency. In the New Testament, you had language of principalities and powers. You have language of spirits. With John, we've talked about these collective agencies. When we talk about, there's a part of our anxiety about this particular technology that is emerging is the fact that now for a couple of hundred years, we have seen wave after wave after wave of other technologies that have completely changed our phenomenological experience of life that have created all sorts of unintended consequences that have global ramifications. Example, I've mentioned this book often in my videos, The Alchemy of Air, about the fixation of nitrogen. At the beginning, I should do a little bit of research before I talk. Here's a great little AI answer. I asked the little Bing chat, world population at the beginning of the 20th century, according to Wikipedia, world population had reached an estimated two billion people at the beginning of the 20th century in 1927. So by 1900, a little bit less than two billion, world hit two billion by 1927. World population at the end of the 20th century, reaching eight billion. We had a century of enormous change, even with enormous genocidal wars and events in the 20th century that killed millions of people. The Second World War, the First World War, many genocides around the world that are famous, millions and millions of people killed. At the same time, the planet went from two billion people to seven point something billion people, or maybe it's six, I don't know, I should check. All right, estimated world population, six point one billion people. The world added four billion people. If you read The Alchemy of Air, there were estimates that without synthetic fertilizers, the world maybe would have a maximum carrying capacity of between three and four billion people. And by the end of the 20th century, we're over six. And this with significant genocidal events throughout the 20th century, notwithstanding. That's the fixation of nitrogen. Technology has been remaking the world significantly since 2007. The iPhone and don't forget there were Windows phones and there were Blackberries, but the iPhones and then Android phones significantly changed a lot about how we live in a very short time. We've only had that technology for less than 20 years. And these are relatively small. And so the panic around AI is understandable given what we realize about our vulnerability to technological change. But what John does a lot of is to try to, again, you know, if you look at his picture there, there's this plaque that says wisdom. His is a wisdom project. Okay, what is wisdom about? Wisdom is about orienting ourselves to engage productively, morally, fruitfully with this astoundingly complex world that we are faced with given the individual agency that each of us possesses to one degree or another. And he frames this in terms of thresholds. Now the idea is that there are moments when everything changes. And the truth is that for the most part we don't recognize the consequence of these changes until they're in our past. For example, Mary Harrington right now is talking about how the reliable contraception and especially ubiquitous contraception became the beginning, was the beginning of human transhumanism. And we would say, okay, that was in the middle of the 20th century. So that was in the past. Would we have said that creating a smartphone with a screen on it that we could use with our fingers and carry around the internet. Now remember it's not just a smartphone. It's the technology, and those of you who remember 2007, it's the technology to actually make the internet productive. So it's email on your phone and it's better texting and it's cameras. Just look at the way that the ubiquity of cameras that can be shared on social media. So again, recognize that this is an ecology of technologies that are coming together. Having that video capacity, we had lots of little point and shoot cameras which were a lot better than the camera on the iPhone or on BlackBerry's long before we had BlackBerry's. But you didn't see the same social impact of smartphone cameras and social media until the other pieces came together. In other words, I think he's right when we're talking about thresholds to pay attention to thresholds. What's difficult is to actually know, anticipate where these thresholds will be. I don't think it's impossible because he makes some of these things that he points out being thresholds I think are true. I think the difficulty, the two big difficulties we're going to face that are one, the fictitious we. Well, we must, and you'll hear this in the talk again, we, we, we, we, we. Well, who's we? Well, humanity. I just hopped over from Jacob's channel where Jacob and Hezzi had their regular fight about the state of Israel. And pointing on them, Americans will have their fight about we're about to have, enter into another season of presidential elections where the whole nation will have its regularly scheduled fight about who will run the country, usually all wrapped up in the imagination that the election is going to be a watershed. And in many real terms, it seldom is because often in America, both candidates for the most part will do a lot of what the other one will do anyway. Now that's controversial. I remember Ralph Nader saying it of George Bush and Al Gore and people looking back was like, yeah, but George Bush and Al Gore, they're really, it's like, well, 50 years from now when they look at Bush and Obama and then, you know, just, just follow along, are they really going to be all that different? Well, we'll see. The difficulty again is the enormous complexity of the world. Even when it comes to history and thinking about history, identifying what the threshold specifically are, for example, the smartphone. Right now it's common to look at the iPhone and say, well, there was a threshold moment, but the iPhone would be nothing without at that point 3G internet connectivity in many places in the United States. Social media and again, these social media networks, Facebook, Twitter, Instagram, TikTok, don't forget some old ones, Snapchat. All of these things work together to create something. And so then what is the threshold exactly? Is it the internet? Is it the smartphone? Is it the social media networks? Because social media, when we talk about that, we're really talking about networks and it's a network of technology, infrastructure and behavior, all of those things coming together. And so when we talk about distributed cognition or even distributed agency, and I'm sure John has a better language for that than I have, we're talking about this kind of thing. And so therefore, using relevance realization to identify a threshold and have a we that agrees on that threshold, there's obviously a lot of skepticism about this. I have a friend who a long time ago met with the, was working for the Department of Natural Resources, Water Resources here in California, and they had this conversation about global warming. And in California, part of the question about that, so much of our water is stored in snow. And so the snowpack is this ubiquitous natural reservoir for water. If temperatures slowly continue to rise, will we have bigger floods? Will we need more reservoir storage, et cetera, et cetera? And the question was, will humanity more easily, I'm not arguing back and forth here with respect to this, will humanity more easily be able to address the cause, meaning, let's say at that point, carbon emissions? Or should we on the other end address the address how we will compensate for the changes? And even though everybody's excited, well, we're going to lower all these things. Most people are like, well, we're probably going to have to deal with the consequences. And to the degree that they were right 40 years ago when they were talking about this, that remains to be seen. But when it comes to something like this, it's really difficult to talk about. So let's, and maybe I should wish you just listen through to the end and then jump to the beginning. The difficulty with this video is if you start at the beginning, I really like the beginning, and then there's a lot of complexity sort of in the middle. And at the end, you sort of get the applications, kind of like listening to the sermon. You get the introduction, which people are there for. You get to all the messy theology in the middle. And then, you know, unless they're dotted with nice illustrations that people connect the stories to, then you get to the application at the end. Let's start with his thresholds. OK, so threshold points. OK, giving them more dimensions of RR, RRR, PP, giving them more of those dimensions. That's it. We can, we will need to do that. Recursive relevance realization. And I forget what PP is. But it's basically taking artificial intelligence out of the browser and embodying it into a robot, whatever language will emerge for these things, in order to, in a sense, put them in our world. Now, my son, who's an engineer, told me something about some of the robots that we have, let's say, on factory floors. And he talked about the fact that they keep humans and robots away from each other because the robots are just sort of big. They don't have relevance realization, at least very, very low capacity relevance realization. But these massive arms, like if you see a Tesla, you see these giant arms, you've got to keep people away from those arms because those arms are swinging. And if you get anywhere near that thing, it's going to kill you. And so a big tension in this video is the conversation. And again, now we're using them. Are these our children or our tools? And now we're using a couple of metaphors there. And it's a really difficult question, but it's a really important question because the nature of it and the uncertainty with what we're dealing with, these are not going to be tools in any way like we've had tools before. Children, I mean, again, in this little live stream, Guy and Hezzi were. So I make artificial intelligence all the time. I have children. And this gets into the really the word that usually sort of slips by artificial because At this point, when I use the, I'd say probably fairly primitive tools that we have freely accessible to us on the Internet, you'll notice I've made some thumbnail. One person said that these AI graphics engines are going to destroy stock photography. And I thought that's right. I thought that's right because stock photography, boy, I can because I can tweak some stuff with those tools and get a little bit more specific than I can get with stock photography. And at least right now, it's free. And stock photography. So children, there's a metaphor that I'm really uncomfortable with. But I understand the analogy because what is happening is that in many ways, human beings are parenting these things. And that's a decision point of our RRPP giving them more of those dimensions. That's it. We can. We will need to do that. And that's a decision point. We got to give them. And again, that's a decision point. Human beings right now have a really hard time saying no to ourselves. And that's a big question. I mean, with what's been happening geopolitically with respect to cutting off China from the most cutting edge chip manufacturing, that's all part of this, assumedly, because as mentioned in this video, two drivers, porn and the military, are going to be big participants in this. And for all of the talk that we've had over the last few years about keeping AI off the internet, it's already been on the internet. We already have a YouTube algorithm. And we have all these other algorithms that are already shaping us. As soon as Bing saw it might have an advantage over Google, it integrated it into Windows, into its Edge browser, into that little search bar. It did it pretty quick. I don't have a lot of anticipation that we will recognize thresholds and show restraint. If we want to genuinely make them intelligent, we have to give them the ability to self-organize so they find these inevitable tradeoffs and learn how to capitalize on them by creating opponent processing that is self-correcting in a powerful way. In other words, we bring them into the world that we are living in. This again is sort of to me analogous to the robotics at the Tesla plant, where we keep people away from those robots because the robots won't know they're going to end your life when that big metal arm swings and hits you on the head. So the degree to that we let these little robots in our lives, we already have little Roombas that are sort of going around. We are probably going to increasingly have little robots in the house that do this and do that, do this and do that. Again, it's going to be sort of a continual process. We're going to have, I think, a difficult time agreeing on thresholds, enforcing thresholds and recognizing thresholds. That's what we need to do. That's a threshold point. They don't currently have that. We don't have to hack our way into that. We can think about it and theorize. We can bring knowledge to bear. And again, it's just the human we is difficult. Second, I've already foreshadowed this, making them embodied and being open to the empirical information about the kind of constraints that are going to come from their substrate. Our substrate, there's a pun, matters to us in really powerful ways about how we're intelligent. Embodiment is not a trivial thing. If we make them properly embodied, and I mean by that all six of the E's, four E's plus two E's as Ryan put it, then we have to be open to the empirical information about that. That's a threshold point, though. Are we going to do this? And let's not let the pornography industry and the military make this decision for us. Yeah, saying no to both of those industries hasn't worked out really well. I mean, and those are just two industries. I mean, we've let Roombas into our house, and you might look at a Roomba and say, it's a Roomba. It's not, there's no artificial intelligence in that Roomba. Tiny little. So then again, where are those thresholds going to be? We already, and then there's a feeling of, I mean, John himself calls the automobile the great American death machine. Yeah, I remember talking to a Haitian pastor in the DR who told me the story of his mother when she first saw a locomotive. He said she ran screaming saying that she'd seen the devil. I can understand that when you think about a locomotive. If you have grown up in a place where there are hardly any machines present, and then suddenly this is where, you know, again, he talks about cargo cults. There is a familiarity that we develop, which isn't always good. Secondly, if we're going to make them accountable and we're going to allow them to proliferate and they're going to be different from each other because these decisions about the trade-offs are environmentally dependent, they will have different perspectives. They will come into conflict with each other. They will need to be moral beings. They will need, we will have to make the decision. Rationality and sociality are bound up together. Being accountable means being accountable to somebody other than yourself. Right. You can't know that you're self-transcending from only from within the framework of self-interpretation. I need something genuinely other than me to tell me that I'm self-transcending. That's what we do. That's how sociality works. That's how sociality and rationality are bound together. We transcend ourselves by internalizing other people's perspectives on us. That's how we do it. I think they will have to do the same thing. But that's a threshold point. Are we going to make that? Is there a lot of work going on in social robotics? You better believe it. You better believe it. It's there and a lot of progress is being made. And can it intersect with the artificial auto-poiesis in this? Yes, but it hasn't. And that's a threshold point for us. And we can choose to birth these children perhaps as silicon sages rather than let monsters appear because of Molochs that are running our politics and our economy. I shouldn't just sit here and emote in front of you and not talk. Human sociality and morality is already enormously complex. And plenty of science fiction plays with these ideas. One of the interesting things about science fiction is this gets to some of the thoughts I had from the early part of this lecture where we have such limited grasp of what's going on. And even the realization of the limited grasp of what's going on is frighteningly rare. You know, we in some ways maybe instead of, you know, maybe we should think about, so we talked about tools and we talked about children. Maybe a better metaphor might be pets. Because pets are sort of the interaction of tools and children. There's a tool-like nature to children. Speaking as a parent, we had five children, small children in our house, and we believed in child labor. That meant that everybody had age-appropriate chores. They had dish duty, they had cleaning duty, they had pickup duty, they had yard duty. They had, we had dogs, so they had scoop, poop scooping duty. If they had their own little pets in their rooms, they had this. And part of the reason that we had pets was to, pets are interesting ways of giving children children in some ways. And of course, you supervise them in their parenting of these pets. And they're doing a tremendous amount of personification with these pets and all of that. And I suspect we will definitely have all of that with respect to these robots in our midst. And again, we don't even know that robot is the term that we will use. You know, and people are, so the replica, this is a digital companion. And again, part of, oh gosh, this is just so hard. This is so difficult. And the more you know about it, the more complex it is. So again, I mean, you know, don't misunderstand my project here. And I do it because I know that John won't. Because I've got enough of a relationship with John to that I think he confidently knows that I, everything that I do with this, I do with both honesty and love. Tell the truth, speak the truth and love. That's the biblical injunction. So, but, and so I, I profited a lot from this video. It doesn't mean that some of the things he says just sort of hit me. And it's going to take me time and conversation to think about it. And even, so theoretically, this threshold idea is really nice. Historically, I'm dubious. Because we tend, we can't, we only recognize, we tend to recognize thresholds in the rear view mirror. And even then, when you watch historians, they can't agree on thresholds. We all know that the French, the French Revolution was an important threshold of sorts. But how? The funny thing about history is that it is always being rewritten because our eyes and perspectives on these thresholds continue to change, again, because of the recursive relevance realization. And kicking myself for, for, because once those, once those, those two P's bubble up, I'll remember them and I'll kick myself. But let's keep going. I think one of the things that's going to happen is that there's going to be a tremendous pressure put on us around these thresholds on our spirituality. Those aspects of us. And this is, I call it the spiritual somatic axis. It's about the ineffable part of our self-transcendence, our spirit, and the ineffable parts of our embodiment, our soul. And I was going to say a lot here, but what he just said right there is exactly right. So if you go back and you look at the conversation I had with Sam and Cale. And then we had a wonderful conversation at our estuary group last Thursday night. The recession technology has already scrambled churches in such a profound way. I mentioned earlier that the challenge of churches by autodidacts. While I think it's still going on. Let me see. Okay. So here's, here's two videos. Jacob continues to, to, to work on just chatting end times edition that didn't seem to come into, didn't seem to come into the conversation too much. But then at the same time, the art of living. Now who's up now? I don't know. But we had, let's see, we've got Trent Sheldon. Don't know Tony Robbins. Oh, he is Matthew McConaughey. Dean Grassiose. See, I don't know who he is. Marie Forleo. Don't know who she is. So in comes Matthew McConaughey and he's got, if you've read his book, Greenlights. He's got sort of a mixture of some Christianity and some, and a bunch of other things. And again, here's a guy that has worked his way into our consciousness Congress. We've made very basic decisions about whether we like him or don't like him. And he's done this through a whole bunch of rom-coms and then some very good serious movies and other projects. He's very, he's good looking. He's popular. He's charismatic. He got his hair fixed. He's got a very engaging story. I know that if there wasn't such thing as a hierarchy and he was my next door neighbor, Matthew McConaughey and I would be great friends. I'm sure we would get along great. But some of you say, yeah, who don't you get along with, Paul? You managed to get along with Jacob. And that's saying something. So, so he's telling his stories. And I got, I got onto this because one of you, I won't say your name, he's a regular in TLC, sent me a DM on Twitter saying, Matthew McConaughey is on the internet solving the meaning crisis. So, okay. And this is part of a point that Jordan Peterson made at his appearance here, north of Sacramento. When Jordan Peterson says, via online pornography, we're already having sex with robots. We're already getting our religion from YouTube. Guilty as charged, right? Here we are. Guilty as charged. And then, and then there's this, this intro for this. I'd never heard of this woman, but then, let's get up to it because there's a big promo for her and here she comes. And come on, come on, come on a little bit further. There we are. Introducing, Oprah introduces her, all of her credentials, all of these other people in this space. Speak about her. She signs books. You know, her books are in different languages. She's been on the Today Show. You know, create a business and, and live the life you want. And we got Tony Roberts saying things about her. All of the signals. So, I mean, this is, this is mega. I mean, a mega church will, will do this. I mean, mega churches and this sort of feedback and forth from each other. And well, here she is, Marie so-and-so and a little bit later. Now this is just running and running and running and running. And this is in some ways stealing, stealing Jacob's ideas. For channels and now we've got people who've only got positive vibes on his cap. So, again, thresholds. I think we've passed one and it's just on screens. And again, churches have had multi-sites with big screens, one pastor, four different locations live. You have a local worship place. You have different locations live. You have a local worship band. Yeah, there's a lot of psycho technologies already in play. We're going to more and more try to identify with that because that's the hardest stuff to give to these machines. And in fact, we can't give it to them. They have to give it to themselves. And we have to figure out how to properly have them give it to themselves. And that is going to put tremendous pressure on us to cultivate our spirituality, to be good spiritual parents. Well, it's going to put tremendous. It's going to tremendously disrupt spiritual institutions. And of course, that's already happening with respect to churches. Churches are tremendously disruptive, as are all sorts of other things. And then you once there are positive and negative things connected with institutions in this space. And okay, it's fine to try to lose the negatives, but they're usually just so completely enmeshed. And to preserve our identity. See, the thing about self-transcendence is it's relative to the entity that's self-transcending. Well, the machines will be greater than with us. It doesn't matter. Think about Captain America, the Winter Soldier. He grabs the thing and he grabs the helicopter and he's holding it there. And we are, yeah, we have machines that are 10,000 times more powerful than Captain America. We don't care about that because it's not the absolute value. It's that relative to him, he is self-transcending. These machines will not rob us of our capacity for self-transcendence. In fact, if we birth them properly, they can help us in it. Now consider YouTube, YouTube as such a machine. Have we already passed that threshold? Are we already participating in it? And if you're watching this video, you and I are both participating in it, as is John. Now, now again, a little earlier we talked about robots and stuff is really hard to think about. Insofar as they are also interested in self-transcendence, insofar as they are interested in loving wisely, insofar as they are interested in being accountable to other moral agents, insofar as they are interested in making persons with... Now again, if we consider YouTube to be a machine, now when I talked to Bali, he said YouTube is a very primitive, the Algo, I just call it Algo, Algo is a very primitive AI and yeah, it's a little kludgy. You can pretty easily manipulate it if you want to. But notice, and John makes this point earlier, where... So they make these machines that can win at Go, but then humans notice how these machines are winning at Go to build other machines that will defeat the machines winning at Go. I mean, again, this is the military. This is what we do. And so there you get sort of the tool question. How are these tools and tools to what end? So when you watch Matthew McConaughey, now I think Matthew McConaughey is thinking that he is making the world a better place. Tony Robbins too and I don't think he's going to make some money on this. I mean, is he sliding into Oprah's spot? I don't know. But again, when you think about YouTube as a machine, as an AI machine that is already among us, you know, Hezzi was, Jacob and Hezzi go back and forth over implants. We already have implants in our bodies in various ways to remedy things or enhance things. And I don't know, I don't know. I don't know. I don't know that the neural link, it's just at this point, it's just really hard to understand what that means as let's say opposed to this thing. Or the screen that I'm looking at right now. Because this is already doing religion. And it's already doing meaning crisis and it's already doing self-improvement. And here it is, road trip, highway to more, thousand bucks, weekly road trip. You know, here you can buy into this event only priced $3.97. And you know, hey, aren't I doing events? Don't we have our quest for a spiritual home down in Southern California? Aren't we doing this? Aren't we using YouTube? Within communities of persons. The existing legacy religions don't have much to help us on this. They make the recommendation become enlightened generally, good, like that, great. They don't really prepare us for this. They don't have anything to say about it. We can't rely on spiritualities that involve the two worlds, that involve magical stuff and miracles, because these machines are coming about without magical stuff and miracles. Get that. Now, of course, this is a long time conversation point with John, because the question of a definition of a miracle, and especially the way I don't think you're going to admonish people out of magical thinking, even if we take it in an enlightenment frame. I don't think it's a different mode of thinking. And it's certainly not one that the vast majority of people will at any time divorce themselves from. People are going to... People already listen for the voice of God through the magic eight ball, or through the lucky dip in the Bible. As these tools, pets, children, come online, this is going to increase. It just is. Get it. Don't pretend, don't avoid, don't dismiss. These machines can possibly be fully spiritual beings in every way we've ever considered things spiritual, without magic stuff, without miracle. Think about it another way. Suppose... Again, YouTube. Apply YouTube. And I don't mean just the algorithm. Just like the smartphone is... The smartphone in and of itself is not it. It's the smartphone plus a network of cellular towers, plus a way to buy the smartphones initially, so there's finance, plus social networks, plus, plus, plus, plus, plus the relationship that we have created with them. All of this creates the dynamic, the disruption, the blessing, the curse. For example, you know, I know... It took me a while to understand that a number of years ago, and for a number of years, guys that I knew that I would expect to have a smartphone didn't have them, and I didn't know why. Were they sort of like the Paul Kingsnorth, Sherry, Nate conversation where they're going to say no to smartphones? Or was it because smartphone was too much of a temptation to look at porn? And in a little while I figured out, oh, they don't have a smartphone because they don't want to have the temptation to porn. And so then you notice it's all of these layers all together. And I'm just checking, picking this because it's the predominant legacy religion. Christian, where do silicon sages fit in the divine economy of the fall and the redemption? Actually, I think a lot of the conversation we're having now with respect to principalities and powers, demons, I mean, one of demons is one of the big list of videos in my head that I want to do a little bit more talking about it just based on the kinds of... Because again, even the comment section. So YouTube as a big AI machine full of human beings. Now, I know what we're talking about because even just with Bing chat or chat GPT, these large language engines that we have, they're different yet. One of the points that I made earlier is one of the big movements that happens is sort of the modulation between monism and dualism. And I think part of the reason that this thing is always sort of going back and forth through time is part of a process of... I don't intend to get Hegelian here, but it's part of a process of collective cognition that we have to try to integrate new things. And so we create these dualities. Again, as I've said before, consciousness is quite monofocal. And so then dualities naturally sort of arise because we can focus with dualities. You can do A-B comparisons. When you get three things, right away the math gets harder. Four, we're just sort of gone. And that's part of the reason, even thresholds. Threshold is in a sense binary. Threshold, not a threshold. And part of the reason why I'm dubious about thresholds is because even looking back at things that most of us would agree to be thresholds, there are way, way more things that haven't sort of risen to our salience landscape and way more things that are integrated. We call it in sort of a Peugeotian name, Gestalt, the French Revolution. But when you read up on the French Revolution, then let's say the Napoleonic Wars, and then Emperor Napoleon, because in many ways it's all part of a package. And the way that, some great lines in the book on the Napoleonic Wars that I'm reading, these people went out, it was so much like Stalin and the Soviet Revolution, where it's almost the same fantasy that Christians and Muslims and other religious groups have, where once I say the magic words, then people will somehow get me and convert and be right there. Now again, every now and then, you say a certain thing and someone seems to flip and it seems to work, but the vast majority of time you say those magic words and people are already resistant to it. Or it's not a new thing. Or it's too new and they can't take it in. You know, the whole Kairos idea. There's not a Kairos moment. So the French Revolution comes along and, oh, this whole idea of liberty, equality, fraternity, and we're going to export the revolution, but the people don't quite seem to be getting it right now, so let's force it on them. And it's like, forced liberty? Don't we have words for that? Isn't that more like tyranny? I mean, in the same way with the Soviet Union. Oh, well, we sort of have to jump start the revolution because, so let's destroy all those particularly politically vulnerable farms in the Ukraine and then you get starvation at a mass level. So, and then you obviously get the pushback. So, finding thresholds again is going to be tremendously difficult. And many of the enduring patterns that are already pervasive in the religious and spiritual landscapes will likely endure and somehow get embodied. For example, to go back to this other video that, let's see if it's still running concurrently. Are they still going on? They are still going on. Join the road trip. And again, when I watch this through the eyes of a pastor having lived my life, I mean, look at the live chat going. To me, this is, I just see all of the pastor tricks, you know. And I don't know that Matthew McConaughey has just sat down and learned them. He's just picked them up watching other pastors and truth be told, pastors got these tricks from television. And on and on and on and on. We're always doing this thing together. These psycho technologies were always passing along, which again brings me to the beginning of the video, which I should have time to play. The beginning of the video where, you know, John lays out some of this stuff because the distinctions at the beginning of the video I really liked. Are they fallen? That doesn't make any sense. Do they have any relationship to the son of God? What? There's nothing in. What if this machine generates a gospel that's as beautiful and as profound as anything in the current Bible? Do you think that's not going to happen? It's going to happen. OK, the difficulty is there are many people out there that will point to many books that say this is more beautiful and more profound than anything in the Bible. This is a monarchical way of looking at it. The questions are going to be, especially the historical questions are going to be, will these other books, will these other books have an impact on society in a way that's possibly relatable to what the Bible has had? And right away you run into the problem of history again where the Bible's been around so long. Often you'll I'll do Internet searches. The second most published book in history, Chairman Mao's Red Book. Well, what do we mean most published? Well, number of copies in print. Well, why were there so many copies in print? Because there are so many Chinese people and they wanted to get Chairman Mao's Red Book into that many hands. I doubt Chairman Mao's Red Book is the second most influential book in all of human history. In all likelihood, Chairman Mao's Red Book will be will pale in significance to, let's say, Confucius or how many other holy books in other religions. So Raj was on the the Jacob livestream and Sikhi is a relatively new religion and Sam was quizzing Raj on it. And, you know, part of what's fun about quizzing Raj on Sikhi, Sikism is, oh, okay, how can I? This is what happens when you hear Raj has all this different language. Jacob will often sort of slip into slip into Hebrew to try to explain concepts in Judaism. So but then you take this other language and then you try to connect it. This is this is what we do. So again, I think history is a good framework for trying to gain perspective and wisdom on what we might be. I think we're already in it to a to a great degree. That's why there'll be cargo culture on these machines. This is not meant to dismiss theology at all. In fact, I think the theological response is ultimately what is needed here. So at precisely the time that we will need our spirituality more than ever, the Enlightenment has robbed us of religion and the legacy religions are by and large silent and ignorant about this. I think they're ignorant. I don't know if they're so silent. Tremendous pressure on us around this. We need to start addressing this right now. We need to address this. These machines are going to make the meaning crisis worse. Here's another way in which they're going to make the meaning crisis worse. Now, now in a let me pull up this podcast. Kel on Twitter sent me a recommendation to listen to Benjamin Boyce's latest podcast in the Matrix, not of the Matrix with Kriptos. And yeah, I've listened to 43 minutes of it of an hour and a half and it is really good. One of the points that he made in there was which I think was a good one when John is sort of trying to assess the legacy religions with respect to the the I'd say the how can we how can we how can we what metaphor even the the the deepening the deepening tide that AI is going to bring in and how that is going to impact legacy religions because again if you think about YouTube as a giant AI machine it's already impacted religion significantly. It's impacted my life. There's Christian YouTube out there. I've got my own thoughts about it. Churches went online during COVID and again just like the smartphone there's all of these different ways in which it comes together. But one of the points that he made is that when COVID hit it tended to religious people not only with respect to COVID but woke ism. What what legacy religions tend to do is put inhibitors in communities. Now this gets people get frustrated with this because if they're on the front edge of something in technology or something in science or something in economics or something in the social sphere religious communities are often seen as problematic because they are resistant to these changes. That's a big function of what religion does. I think we are going to see we are going to see ways in which religions interact with this and in that interaction we're going to learn some things again for example men that I know that don't have smartphones because they don't want the temptation to pornography in their pockets. Married men who don't want not necessarily pornography but distraction. So there's a lot of parents who their children never see their smartphones because the parents never pull out their smartphones in front of their children. There's ongoing Christian debates with respect to all sorts of new technology where religious communities tend to discuss there's a much more of a we in the religious community than there is sort of out there in the general population. A lot of good stuff at the beginning of that in the matrix not of the matrix but stuff for me to keep focused. We need to start to think about the future of the world. We need to start to think about the future of the world. We need to start working on this right now not only for us but for these machines. This is my proposal in the end of how we deal with alignment. Make them care about the truth. Make them aspire to loving more wisely. Make them long for the truth. Make them love more wisely. Make them love more wisely. Make them love more wisely. Make them aspire to loving more wisely. Make them long for enlightenment. One of three possibilities. They never become enlightened and then we know what our uniqueness is because we've had individuals who are unquestionably were enlightened. They become enlightened. Then they will want to enlighten us. Why? Because that's what enlightened beings like to do. Right? Or maybe not. And then they go to the silicon equivalent of Nirvana. This last little trio is really interesting because what he says a little bit earlier, again, part of what we keep bumping into because these technologies so deeply impact our arenic perceptions and realities is religious anthropology. What in fact are we? And so as I said again in that one question and answer, a big part of what's happening in this little corner is in modernity, with what modernity did, it sort of accentuated a dualism and perhaps Descartes was a big piece of that. And what we're trying to do because it's very hard to live in that split world. And so when I think about what John talks about in terms of a two worlds mythology, I think about which two worlds mythology. We have so many of them. And I think part of the reason we have so many of them is again because of this nature of consciousness. This is the way that we deal with things. And often you can sort of align up these different two worlds mythologies and you can find overlap and things that are consistent with them. But another piece of what's difficult with this is the challenge of the point in the river. It's the same challenge as thresholds. It's like saying even when we say use the word enlightened, this is very much going to be part of what we get into with the quest of the spiritual home. What on earth do we mean by that word? Obviously it's connected up to similarities in religion of participation with God, theosis. Protestants tend to want to use godliness. I mean godliness and theosis. Are they really that far apart in terms of words? And again listening to Raj and his Sikhi, you can see the deep impact of all of the religions that were there in that area of the Punjab and northern India and that fairly recent religion. You can find clearly elements. Christianity was there. Islam was there. All of these Indian faiths were around there. And you can see elements of all of those in the Sikhi religion. So is YouTube enlightened? Does YouTube have the capacity to help people towards enlightenment? And I think John is right where part of what we deal with in the world is there's always sort of two centers to the world. There's me and not me. And we are sort of little centers of the world, but we realize that we're not really, our pond is not sufficiently deep to be the center of a very good world. And I am an insufficient god. And so then there's the rest of the world. That wasn't terribly eloquent. Let's finish this off and then jump to the beginning because I loved what he did at the beginning and I found it sparked a lot of thoughts. In any of those, we're winning. If they're not, if they can't be capable of enlightenment, we find what is ultimately unique about us. If they are and they make us enlightened, then we don't care about how greater than us they are. We're enlightened. We relative to our own capacity for self-transcendence, we're maxing out. Remember Captain America? We love it. And if they leave, they leave. I've thought about writing a science fiction story that people have to keep artificial intelligence to a certain level because when they cross the threshold, it evolves in this way, like the movie Her. And then the AIs just leave. And so if we want to make useful tools, we have to keep them at a certain level, constrain them, because if we allow them to go beyond it, they just leave. So I don't know if that's anything more than a science fiction story, but it's a good one. But here's the thing, right? Make them really care about the truth, make them really accountable, make them really care about self-deception, make them really long for wise. Accountability is such a tricky thing. We wrestle with that with each other. And again, as someone who deals with people in Christianity, one way of thinking about the history of legacy religions is attempting to make God or the gods accountable. So we're loving what is meaningful and true, make them really confront dilemmas, make them capable of really coming and staring into the abyss so that it stares back through them. Do all of this. Make them long for enlightenment. That is something we can do. Oh, silly, John. Proposing universal enlightenment. Really? In a time of imminent gods, you're going to tell me that the project of universal enlightenment is silly? Great point, John. David Bentley Hart. I mean, this is what, I mean, one of the big debates that continues in religions, including Christianity, is do all have hope? CS Lewis wrestled with this. This is exactly what religions always wrestle with. I think you should stand back and reframe. That is the end of my presentation, my friends. All right, let's go to the beginning. Because I was a little hesitant to start at the end. But because it's so focused on thresholds, he had the list of thresholds at the end. And the beginning, I think, to sort of set up the problem was for me part of the video that I found super productive because he just raised things and it was like, I hadn't thought of that. I hadn't thought of that. I hadn't thought of that. So I found it really provoking and challenging. It's going to be the following. I'm going to go through sort of an argument per section and then I'll open things up to take comments, questions from both Ryan and Eric. So the first thing I want to do is talk about the predictions. One of the things that are happening with the GPT machines is we're getting a swarm of predictions. And many people are finding this challenging because the predictions are quite varied. Many of them are inconsistent with each other or even challenge each other in a fundamental way. I'm going to try and propose that we try to be more careful about the predictions. We try to steer ground between hyperbolic growth predictions that these machines are just going to hyperbolically accelerate in intelligence. And that that forks into two variations. Utopia is just around the corner or we are doomed to doom, doomed forever doomed. And so let's let's be a little bit more cautious. I'll give you some reasons for that in a minute. We also want to be steer between all of that, both the positive and negative hyper hyperbole and then a kind of stubborn skepticism that's digging its heels in and saying, no, this is not a GI. It never will be. This is this is decades and decades away. And there are people making these arguments. And I think that is also incorrect. I think the attempt for whatever reason to dismiss these machines is not proportioning our evaluation to the reality that they are actually presenting to us. So what I hope is that we can get much more careful and that getting more careful about the predictions we're making will also will also in conjunction with the arguments and discussion we're going to have allow us to allow us. Me, me, me, maybe specifically to propose some important threshold points that we have not yet met with these machines, but that we can reasonably foresee not perhaps their timing, but why they are pivot points and that these are points where we can make fundamental decisions about how we want to go forward, forward, especially in terms of the spiritual challenge and the enlightenment issue. So why do I why am I skeptical not about the machines? I'm critical, but not skeptical. And that important that distinction is going to be important throughout. I am skeptical of jumping to conclusions about hyperbolic growth, since human beings are famous for jumping to conclusions when they see hyperbolic growth. And if you don't, I think this is a lot of Sam's point in there. Believe me, just track the history of the stock market or something like that, and you can see that people can very often get taken up by it. What we can say is most often hyperbolic growth is found within self organizing processes. And when hyperbolic growth is within self organizing processes and the economy is a self organizing process. It usually is part of a larger, larger pattern called punctuated equilibrium. You can see this also in the history of evolution. There'll be so after the asteroid hits, there's just exponential speciation in geological time. But time scales matter. And we'll talk about that later. And then it flattens off as the niches get filled, as constraints emerge, as more. So we don't know yet if this like when people just draw these graphs, look at what's happened over the last five weeks. Right. It's like, yeah. And then you need to remember we got similar predictions about self driving cars and the exponential growth. And soon all these people would be put out of work. And this is a truly important point. And you can see this all over the place. Some of you might remember again, it helps to be old. It helps to be old. I can remember computers in the early days. And you look at processing power, you know, you look at this, you look at this growth and processing power. It's like, wow, all this processing power. Just remember some of those of you who are younger, those you remember, you look at that iPhone, that original iPhone. And I remember reviews of it because, you know, I was watching it. I was thinking I was on a different I was on a different I was on Verizon and it was on AT&T. But, you know, very fair critiques of it were saying, you know, your BlackBerry will do better for you. Probably. You have that mechanical keyboard, you remember the little little ball in the middle of it some some way. I still have some of these old phones here. And then, of course, every, you know, your Snapdragon processor, you know, would get would get better and better and better. And it seemed like every year if you bought the next year's phone, smartphone, you got that much more capacity. The camera was better. The processor was better. The battery life was better. The operating system was better. It kind of went back and forth. You'd have stumbles with the operating system, et cetera, et cetera. Android and Apple, iOS were sort of fighting in terms of things. And you reach a point now where, you know, the smartphone's a year and a half old. It works absolutely fine. And I'm pretty demanding on a smartphone. I'm kind of picky about it. And I pay attention to it. Same with PCs. The PC I built here with a this one has a 12th generation core i5, the better of the two. It has a it has a decent as a decent graphics processor. All of it is sufficient to what I need. And this computer compared to a computer, a 10th generation, a ninth generation, a sixth generation, sometimes if I need to help somebody out with a PC, I'll go to Newegg and I'll buy an old Lenovo. Think, think, you know, think pad and I will, you know, it's a fifth generation processor. It's a sixth generation processor. You can tell it's not up to speed, maybe get an eighth or a ninth. But in terms of the use of the computer, not that much more functionality. Watching YouTube's typing out a Word document, running my Logos Bible software, even doing some of the rudimentary video editing that I do. Don't need that much horsepower. Maybe if I have to re-render a video, I'll like some of the new horsepower and some of the machines. But for the most part, and it's been this way for a long time. I build a new computer, not noticeably faster than the last one. Whereas back in the early days and you see this all over the place in many, many, in many, many realms where it seems like things are going to take off. But there's a constraint. We don't have self-driving cars. When I got to Sacramento, a member of my church was an engineer working at Mueller, Molar Air Car. And you can look that up and you can. They've been working on flying cars since the 60s. When you actually start working on some of these things, you begin to realize again, just like with a cell phone. I mean, we've had little computers we could carry around in our pockets and do certain things, things with. But it waited for all of the other infrastructure to hit a point of, as John would say, criticality where then something changes and you sort of get a whoosh and then a plateau and then a whoosh and then a plateau. And this is this is the way things go. So when you hear all of this talk about we're going to have this increasing, we're going to have we're going to have chips that can do so much. Well, it isn't just a matter of the processing power and the and the ability of to make to do calculations. Plus, you have the fact that you have CPUs and GPUs. And remember when everybody was mining Bitcoin in China and you couldn't get a graphics card for your computer? They weren't you know, the Intel core chips weren't selling like crazy. It was all the GPUs. It was Nvidia or AMD that were selling those kinds of. So in other words, there's a lot more going on here than just say processing power. And also think about think again about the Internet. Think about YouTube. Now, obviously, if you have a nice fiber connection, you have a decent processor. But now almost any processor will run YouTube for you. It's not the processing power. It might be the it might be the your Internet speed. But what really makes the machine of YouTube the artificial, the religious artificial intelligence engine is the connectivity. Now, the idea is that and you'd be again, we've been on this trajectory for a long time. If you think about the World Wide Web gets going and then you had Yahoo and what was Yahoo? Yahoo early on were people making lists of websites, people making lists of websites. What did Google do? Google took a look at searches and with its algorithms said, we're going to prioritize in the hierarchy. We're going to prioritize web pages that more people are clicking on. So then you had search engine optimization. Again, this is like the go game. It's search engine optimization. And so now suddenly there's search engine optimization now on YouTube. So if you if you do anything on YouTube, you have, of course, the thumbnail is the thumbnail very click baitable is the title click baitable. Will it get attention? Will the video hold the attention again and again and again and again? There's all of these things are the nexus of multiple variables that give us this sense of intelligence, this sense of enlightenment, this sense of relevance realization. It's not going to be one thing. It's going to be it's it's going to be deeply areanic as well as agentic. And that was like 2012. We're 11 years later because we hit a plateau. There was the exponential growth and we hit a plateau. Now, I could be wrong, but the reasonable thing is to be agnostic about the meaning of this very low resolution measuring of exponential growth. I mean, here's another example. Consider if you were at the beginning of the 20th century and measuring all the breakthroughs in fundamental physics and you would see this exponential growth, relativity, quantum mechanics. And then it plateaus. It plateaus and it's been 50 and more years since we've had a significant breakthrough. Eric Weinstein talks about this. And this is where I get to the point of. How can we best? What kind of areanic imagination can we employ that affords us wisdom and gives us the best sense of how the world works? We all walk around with these models and narratives and stories and pictures about how the world works. And again, the. Traditional perspective, which is built into Christianity and other religions, is one that is a model. Of spiritual agents that move through people. And again, I think it's I think that model in many ways is superior. But again, I go back to the illustration or the example that I use of school spirit. School spirit is not somehow divorced. School spirit is not somehow divorced. From human agency, human agency is all over school spirit, but. Try as they might. School spirit does not bend the knee to the principal or to the student body leader or to a teacher or to the governor. All sort of participate in school spirit. Now, where people get. Part of the difficulty that we have is we have this nature, super nature distinction, which is not very old. And is a product of. A lot of thinking, some of it very helpful. We found this is why I often call it the. It's something that we discovered was super helpful in dealing with. Small problems. And then we sort of said, well, this is true of all big problems, too. We don't know that. And so, OK, so if we stay agnostic on that level. The next question is, is a model that has. That that engages with the world. With let's say spirits. A more accurate model than one that imagines individual human agency really controls much of anything when it comes to human communities or human history. And I think. We don't know. We don't know. And that is where we should properly stand about this. So we have to instead of making predictions that are not well warranted, we should try and foresee plausible threshold points. Not predict necessarily. But foresee them and foresee them as our opportunity to steer this and empower. OK, so we already talked about thresholds. And again, I think a super important one that I agree with him is. The creation of. Once you use the word more, you sort of lose threshold, even though threshold is in. Is in there. I think the threshold that he talks about in terms of. The robots among us is a big one. And but but again, we're talking about the robots among us. And but but again, I think part of. The difficulty is again, our imagination, because in many ways these PCs and these screens and YouTube, where where is YouTube. YouTube is sort of Godlike. In that it's almost ubiquitous, not in all places of the world. You can go places where you can't get a cell phone, a cell phone signal, but it's it's almost ubiquitous, but we don't think about it in those terms. The alternative I'm proposing. See, as you get into exponential growth, things are often disclosed that you did not foresee within your normal framing. Let me give you one more analogy on this point. Traveling faster and faster. Traveling, we could travel faster and faster. And here's an exponential growth in our ability to to speed through the universe. Why aren't we flying around in supersonic jets? It's not necessary. The cost, it's cost prohibitive. The Concorde seemed like a great idea. Didn't last long, didn't take over. Why did jets overtake props? So is supersonic flight a threshold or are there other thresholds in this? Amazingly complex reality of economics, environment. Are those we're going to have that we very much have this with space. OK, we went to we. Some human beings went to the moon. And now, OK, we're going to go to the moon and we're going to go to Mars. And well, why haven't we? Well, sky isn't the limit. There's lots of other limits. Well, as you do, micro particles become relevant in a way they are never relevant for us in our daily movement. Right. There's a video online. What happens if a grain of sand hits the earth at the speed of light? Because force equals mass times acceleration. So it's accelerating to the speed of light and it hits the earth and you have this titanic explosion. This is why interstellar travel might actually be a great way to do it. This is why interstellar travel might actually be impossible for us, even if we get machines that accelerate us towards the speed of light, because things that weren't constraints can suddenly become constraints. And of course, the speed of light constraint is also there for all the fiction around faster than light travel. It's a real constraint. Again, this is meant as an analogy. We don't know what constraints will be revealed. We don't. And simply looking at a simplistic graph is not taking that into consideration. We are genuinely ignorant because, as I will make clear as we go through here, we really do not know how these machines are producing these emergent properties that they're producing. And therefore, trying to draw something like scientific predictions from ignorance of the underlying mechanisms is a seriously incautious thing to do. And you know, when he says emergent processes, I mean, when you use chat GPT or Bing or Dali or Mid Journey, any of these things, you, something happens to you. Why? We don't know. It doesn't happen the same to all of us. Some of us do this and some of us don't. Some of us, it starts and we're doing it right away and we're playing with it. Others of us, not at all. How then does that go through the world? I mean, all of these points that he makes early on are really important. And unlike how many of the, I was just, how many of the pundits on TV, oh, this AI thing, what do we know? So we have to pull back from that. Now, I'm not saying we shouldn't try and foresee, but notice my shift in language. I'm shifting from prediction. At this date, this will happen to foreseeing. What's the foresight? The foresight is, can we foresee as we bring real explication to these, can we foresee threshold points where we can reasonably make a change? I think we are in. See, and when he says we make a change, it's not going to be humans. It's going to be the spirits that move through us. Again, I was, oh, okay, so the rest is history on Vietnam. Why did the United States fight the Vietnam War? I mean, the French had basically lost and the U.S. Well, we didn't, we wanted to stop communism because we were sure that if Vietnam fell, then Indonesia was right behind it. Now we look back and we say no. The various perspectives that we have had on the Vietnam War, and it was interesting listening to the podcast because Tom and Dominic were talking about the deer hunter. They were talking about apocalypse now. And, you know, these are these are credible historians. Now, Dominic, this is more his area of expertise, so he had read more books, but we were not in Vietnam. Some people were. Well, what does that mean? What on earth does any of this language mean? And so what you see, even with a little thing like the Vietnam War, you have these waves of. You have these spiritual waves that sort of possess groups of people in the body politic. And again, they're not in any way, they're not in any way monolithic. For example, the only thing more unpopular than the Vietnam War were the Vietnam War protesters. The Vietnam War was a very popular war for much of its time. But a certain group of people were not happy with it and they won the fight in a lot of ways. Well, why? And but you wouldn't know you wouldn't guess that looking back on it because there's all of this cache and the culture about protesting the war and being against the war. And but you get back to this question where human beings were we. Gosh, how to get away from this. Human beings are really limited at perceiving our world in any we-ness. We we project onto the arena. And we need to project. We need to in that way, in a sense, transjectively construe the arena so that we can participate productively in it. But what's what's really changing again, if you read his if you read a lot of history, you'll see that. And even reading history is it's a very high view. I'm reading this book on again the Napoleonic Wars. So much so much detail just escapes me. Very low resolution. The rest is history on the end of the Vietnam War talked about the fact that there's almost no named characters in Apocalypse Now, this movie that's tremendously influential in the Vietnam War. That's tremendously influential in Americans remembering the war. There's almost no named characters that every Vietnamese. Born in the Fourth of July, there's another Vietnam movie. Forrest Gump is at least partially a Vietnam movie. But yet to not sort of collapse into solipsism and to understand that we do live within an arena and that arena is real and resistant to our projections and that our projections need to continually be recalibrated in order for us to actually function within the arena and have agency within the arena. A Kairos. We are in a pivotal turning point in world history. Maybe one of the greatest, maybe the greatest. I don't know. I would need to be godlike to be able to make that pronouncement. But, unfortunately, I'm not, which is something I'm also going to talk about later. I don't want to be a god. I hope you don't either. Imagine having a godlike ability to remember for all of eternity all your failures. I don't think that's an existence to be desired. So if you were godlike, would you have failures? I think we need to be really careful. I think we need to pay attention. Depends on the god. To what we've seen in the history of science. The past century has not been the century of unlimited growth and knowledge. In some ways, yes, more and more data, more and more information. But you can be misled by just a quantitative approach. Because if you pay attention to what's been happening at a philosophical, epistemological, having to do with the study of knowledge level, what you've seen is this has been the century of the accelerating discovery of intrinsic limits on what we can know. And this was part of the point that was made in that plastic pills video where I made it with the ContraPoints video. Just look at streaming TV. You have more to watch on television than any human being has ever had before. Is it any better? I mean, were you happy watching, having three networks and watching Happy Days? The realization that the Cartesian project of unlimited knowledge is not actually a possibility. It is reasonable to conclude. Again, I'm not speaking timing here. I'm talking about trajectory, but it's reasonable to conclude that this trajectory will continue and show itself in this project as well. We are going to perhaps start to discover the kinds of fundamental limits on mind and its interaction with matter that were not previously available to us. And that will be welcome. But I think it's unlikely that the machines will just in some simple exponential pattern grow. One of the reasons I think this is because there's an issue of what's called general system collapse. This comes out of general systems theory. And the place where we have evidence for this is in civilizations, which represent very complex intelligence within sophisticated distributed cognition that's intergenerational in nature. So this is a very powerful cognition at work. I mean, and if you stop and think about it, the GPT machines are basically just taking that collective intelligence from distributed cognition and putting it into a single automated interface for us. So if you think the GPT machines are very intelligent, you should think that civilizations are equally that kind of superhuman intelligent. That's a reasonable thing to conclude. What do we know from the history of these civilizations? They face general system collapse. Why? Let's take it that reality is inexhaustibly complex, not just complicated, but complex. Right. And it contains real uncertainty, not just risk, real emergence. And by the way, when you have real emergence, you have real uncertainty, not just risk. And all of these people are invoking real emergence when they're talking about these machines. So real emergence means real uncertainty. Real novelty. OK. Now, so you place superhuman civilization intelligence into a complex environment. What do you see the system doing? Becoming more and more complicated, adding more and more components, bureaucratizing itself in order to deal with problems. But what you get to is you get this this sort of fact. As you linearly increase the number of problems you're trying to deal with, the number of interactions within your system is going up exponentially. So at some point, managing yourself becomes as problematic as any problem you're trying to solve in the environment. And then the system, the system gets there. There's a very interesting tweet. I think I might have grabbed it on my blog. No, I don't see it. It's basically again about AI and ethics. And so part of what they're trying to build into. So you have these you have these language engines and they're trying to build. Well, someone asked a question I did the other day. Sort of I was going to have if you remember my rough draft for Sunday, I mentioned that Peter gets eaten by the fish. And so I thought, well, let's see if this thing can cook up the Apostle Peter getting eaten by a shark and the AI engine wouldn't do it. It's like, no, no, no, we can't we can't do this. And it's like that didn't come from the engine. This is, you know, Apostle Peter eaten by a shark. Why not make that? No, this would be this would be insensitive to certain religious groups. What do you mean, my religious group? No, some people would be upset by this. So, OK, you had to build this into the engine. Well, think how many ways you can make people upset. And if you think if you think people who are sort of being nannies and busybodies with respect to all kinds of things out there in the real world, once they really get a hold of representation and the search engines, they're going to be putting rules on these things like crazy. And they're going to be, you know, for a lot of people increasingly useless. And this is the point John's making. As it said, top heavy, it gets over bureaucratized and it collapses. Now, this is a regular pattern, regular, reliable pattern for the superhuman intelligence that we find in civilizations. I do not think it's reasonable to conclude that these machines will somehow just avoid that problem of, you know, exponential growth in intercom complicatedness as they try to deal with. Real problems that contain real uncertainty that an inexhaustible environment is presenting to them. Now, that doesn't mean I can say, oh, well, they're never going to surpass us. John Vervecky is not saying that John Vervecky is well aware already of things that can surpass him. And like I said, it's very clear that we have been relying on the superintelligence of distributed cognition that is distributed across people and across generations for millennia as the sort of an important source of normative guidance to us. And in that sense, we've always been working with a different kind of, let's call it collective intelligence. So then you begin to ask the question, well, what do we mean by artificial? Because again, back to the video, the chat we're having, well, I've made artificial intelligence. I've made five of them and they all have names and they're running around in the world and they're, you know, they're having jobs. And finding partners and making careers and they're going to have this trajectory. And yeah, they're my children. Well, artificial. What do we mean by that? Is my pet an artificial intelligence? These machines, it's not unreasonable that they could reach that level and maybe, and we'll talk about this later, having a different substrate, the material they're built on may allow them to go to different levels. I do not think, though, that they can just grow exponentially indefinitely. I think that is we have no good reason. And I'm trying to make arguments here for believing that. And that means we can think about these machines, however godlike they might be, as being inherently still finite in a matter, in a manner that really matters to their cognition and their attempts to make sense of themselves and their world. And that's going to be an important linchpin later on in my argument. What's interesting is there's some evidence that we are very close to all the trade off points, at least for biological beings. For example, there's all these you curves for like if speed of transmission, if you speed up the speed of neuronal transmission, we're at sort of the maximal sort of the optimal because if you go too far, you get into diminishing returns and the negative side effects start to manifest faster than the gains. And also for more neurons. And so I've seen some really good arguments that we're sort of peak biology. And that's very interesting. If you think about it, that's might be, of course, why we resorted to culture because culture allows us to supersede the limits of peak biology. We. And when again, When you look at what is what what about human beings? We always compared to primates. What about human beings? Are we smarter than the primates? There's a lot of arguments that say we're not really smarter than primates. What do we do that the primates don't do? Well, we have culture and we have networks and. Whether you're a skeptic and you think that spirits are only emergent or you're a religious person that says, no, it could very well be that the world is doesn't have a lid on it like that. And that, in fact, we are all the way back. We are the product of. A spirit plus the influence of other spirits. Teeter. On the edge of despair and madness. And as these machines approach their own threshold. They will plausibly also teeter on the edge of that. And that is something we need to think about. And I'll give you more precise reasons as as to why that is going to become important. It has to do with the increase. We'll have to increasingly these machines will have to increasingly rely on more and more pervasive disruptive strategies. And so we'll come back to that. All right. One more thing that I'm going to. Say about this is. And this will go into this more detail, the rationality. Of course, we have to make the and this is where the general system things really starts to bite. These machines have to become more self monitoring and self directing. In very powerful ways. And then the problem with that is if you make this system as powerful as this system, then you get into an infinite regress. One thing you don't want is a large language model. Right. Making all the hallucinations and repetitive actions and weirdness. Trying to evaluate a lower order LLM that is making all kinds of hallucinations repeated because then you just get an infinite regress. So you have to properly have this the heuristics operating at this level to be different in kind than this level. And that also gets you into a diminishing return. And this is this is this is where the physical world because again it's a world of constraints. I'm running out of time, but he does talk about constraints a little bit later, which is really important. It's this world of constraints that that really helps. Just look at our language. We keep keep us grounded. Issue because at some point you know you don't want this to become as complex as this and think about it already. I mean, these machines have hundreds of billions of parameters. You know what it's like to try and track 100 billion parameter system. You know how that you know one of the things that this machine that probably has more than 100 billion parameters can't do very well is track 100 billion parameters. Right. So just thinking that the whole we can just stack these on top of each other, I think, is also overly simplistic. We're facing there's real trade off relations. There's real problems there. And again, that means that these machines are going to be finite in a very important way. And they will confront presumably the issues around finitude that will be analogous to ones we have now. I want to stop here. Not I'm not finished this section, but I want to make clear all these gaps in the G of GPT machines do not take them. I'm not offering them as any grounds for dismissive skepticism. I'm confident that we can approach these limits and that we and we'll continue to make progress. And I'll point some of the things that are already happening. That's not why I'm doing this. What I'm doing this for is I want to show that these machines are not yet fully intelligence. Nobody really thinks that. They talk about sparks in the beginnings. But I want to unpack that common claim. It's unlikely that they're currently conscious. And what that means is we face thresholds about qualitatively improving, not just quantitatively, qualitatively improving their intelligence, possibly making them self-conscious, rationally reflective, et cetera. And that's what I'm most interested in. What are the threshold points we can get to? How can we make them plausibly? So if we just give up. Oh, right. And no, no, no. There's going to be trade off. No, no, no. It's so funny. I never noticed that in him until somebody said it. No, no, no. There's going to be limitations. There's going to be, you know, all kinds of stuff. And then from that, we can pick off. OK, here are plausible threshold points. And then we can more finely tune our response to the alignment issue. That's why I'm doing this. I am very impressed by these machines. I think it is very reasonable to conclude they are going to significantly alter. I said it. There are Kairos are going to significantly alter our society and our sense of self. They are going to. And again, that is already happening. And I agree with him that it's going to continue. What that looks like in 2005, people were running around with their flip phones and the most powerful corporations in the world imagined phones were going to get smaller and smaller. And before you know it, the screens were getting bigger and bigger. And then the screens and who knew what what size, you know, the screen needed to be. And we don't know. Do they are going to pour meth and fuel on the fire of the meeting crisis. And that is something I think we need to take into account. That will tempt us to respond inappropriately to what these machines are presenting to us. And that leads me to some final and that will happen sort of societal predictions. I think there's going to be multiple social responses. And as I said, I'm worried about the accelerant of the meeting crisis tempting us towards inappropriate ones. So one is nostalgia. People longing for the time before the machine. People longing for the time before the machines, longing passionately and deeply for the golden age that you did not realize that 10 years ago you were in the golden age. But 10 years from now, you'll be hearing you were in the golden age, that wonderful time when there wasn't GPT or whatever AGI takes its place. What? Just hang on. Louis the 14th. When he grew up as a young kid, the nobility staged a coup and he remembered that. And he vowed that when he became king, he would crush the nobility and become an absolute monarch, an absolute king, the sun king, the king of the sun, the king of the sun, the king of the sun, and the king of the sun. Louis the 14th, an absolute monarch, an absolute king, the sun king, l't c'est moi, I am the state. That's Louis the 14th. In crushing the nobility, read about Chairman Xi and the Cultural Revolution, he disenfranchised a whole segment of the population that had traditions of power, traditions of decision, because they generally ate better, highly educated because they had access to education, and they were disenfranchised. That's a bad idea, because that is the basis for the beginning of revolution. So I'm saying that now to the people who hold power. I'm talking to all of you right now, you who think, ah ha ha, yes, 95% of the people are going to be driven, but I will become a sun king. I will. Be careful. You are lighting the fires of a revolution in a kairos time and thinking that you will be protected from those flames, I think is foolishness. What else is going to happen? I think that combination of nostalgia, resentment, and rage will have multiple religious consequences. One, and religion is going to figure in a lot of what I'm talking about today. It already is. One of those is what you get when you mix nostalgia with resentment and rage, you get fundamentalism. Fundamentalisms are going to rise, and they're going to be increasingly apocalyptic fundamentalisms. And fundamentalism and apocalypse go so nicely together. They really, oh, apocalypse, fundamentalism. Oh, I love you. I love you too. Right. That's what's going to happen. And so we have to think about how that can shade off into a kind of escapism. I don't have to worry about this. God will come. This is just the Antichrist, et cetera. Now, I'm going to say one thing to my Christian friends, and I want you to take this really seriously. For those of you who believe in that, I hope you're right. I really honestly do. But I want you to consider the fact that there have been multiple times, Kairos says, where God has been silent. I suspect that is very possible now. Define silent. Another thing that's going to happen is cargo cult worship of this AI. There's already, I forget, sorry, I need an apology. I forget the author of this article I read. He didn't specifically make this argument, but it overlaps. And he has definite providence and precedent. I just forgot his name. I'm sorry. But he's got an article about how people will probably start worshiping these AIs. And I think that's the case. We'll have a cargo cult around these emerging AIs. What's a cargo cult? So during the Second World War, the Americans flew in to the islands in the Pacific, all kinds of cargo, all these goods that the Indigenous people found wonderful and amazing. And this stuff is just landing from the sky. And then the war was over, and the Americans left. And the Indigenous people started building out of wood, and they started building out of wood, and they started building out of wood, and they started building out of wood, and they started building out of wood. And the Indigenous people started building out of wood what looked like airplanes in building runways because they were trying to get the miraculous airplanes to return and dispense their wonderful cargo. So I mean, cargo cult around the cargo that these AIs can dispense to us. I think that's a very reasonable possibility. And I think that is also a very dangerous path to go down because that will actually distract us from the hard work that we need to do in order to properly address the alignment problem. There's going to be a lot of spiritual bypassing, which is I am spiritual. It doesn't matter, right? A lot of escapism, drugs, pornography, et cetera. Tragic disillusionment. Tragic disillusionment. And that's going to exacerbate the meaning crisis. Then one more thing, and there's a fork here. This is around identity politics. Wow, I'll leave that as a teaser for you because we know that the YouTube loves identity politics as a big clickbait. So I think this was especially, again, I wanted to get the thresholds and I want to talk about thresholds, but I wanted to get a lot of this beginning in two because I think in the beginning, you really did a good job of saying, okay, slow down. Think about some of these things because in the media right now you hear sort of runaway train ideas. Okay, but it's all very low resolution thinking and sort of fear based. And again, I think a lot of these thresholds we've already passed. Now that doesn't mean that there aren't other thresholds, but I think we're going to really, we're going to struggle both with the idea of a threshold and the idea of we. And I think generally speaking again, that which moves history is best and often frustratingly seen as spirit and spirits. It's a quote I want to get in here. I should find it because he says it basically, he basically says the same thing. I can't find it quickly and easily and I have to go. But yeah, I enjoyed listening to it. There. We are not done talking about this. But it'll be interesting to see how we talk about this with respect to the larger technological conversation. Anyway, let me know what you think. Leave a comment.